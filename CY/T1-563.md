# Cybersecurity Study Guide

## 1. Basic Components of Cybersecurity

### **Threat**
A potential cause of an unwanted incident that may harm an information system or organization. Threats can be intentional (e.g., hackers, insider attacks) or unintentional (e.g., human error, natural disasters).

### **Vulnerability**
A weakness in a system that can be exploited by a threat to gain unauthorized access or cause damage.  
Examples: outdated software, weak passwords, misconfigured firewalls.

### **Safeguard (Control)**
A protective measure implemented to reduce or eliminate risk by addressing vulnerabilities or deterring threats.  
Examples: encryption, multi-factor authentication, firewalls, employee training.

### **Target (Asset)**
Anything of value that an attacker seeks to exploit or destroy.  
Examples: data, hardware, intellectual property, reputation.

### **Exploit**
The method or code used to take advantage of a vulnerability.  
Example: a phishing email delivering malware through an attachment.

### **Loss**
The negative consequence resulting from a successful attack.  
Can include financial damage, data loss, operational downtime, or reputational harm.

### **Risk**
The probability and impact of a threat exploiting a vulnerability.  
**Formula:**  
`Risk = Threat x Vulnerability x Impact`

### **Zero-Day**
A previously unknown vulnerability that is exploited before the vendor releases a fix or patch.

### **Impact**
The magnitude of damage that results if a threat is realized.  
Types: financial loss, service disruption, legal liability, reputational damage.

---

## 2. Threat Vectors and Common Attack Types

### **Threat Vector**
The path or means by which a threat actor gains access to a target system.  
Common vectors:
- **Email:** Phishing, malware attachments.
- **Web:** Malicious websites, drive-by downloads.
- **Network:** Man-in-the-middle, denial-of-service (DoS).
- **Physical:** Unauthorized access to devices or facilities.
- **Supply Chain:** Compromise of trusted vendors or updates.
- **Removable Media:** USB-based malware spread.

### **Common Attack Types**
- **Phishing:** Deceptive messages tricking users into revealing credentials or installing malware.
- **Spear Phishing:** Targeted phishing against specific individuals or organizations.
- **Ransomware:** Encrypts data and demands payment for decryption.
- **Denial of Service (DoS/DDoS):** Overwhelms a system to make it unavailable.
- **SQL Injection:** Manipulates database queries through input fields.
- **Cross-Site Scripting (XSS):** Injects malicious scripts into web applications.
- **Password Attacks:** Brute force, dictionary, or credential stuffing.
- **Man-in-the-Middle (MitM):** Intercepts and alters communications between two parties.
- **Malware:** Includes viruses, worms, Trojans, and spyware.

---

## 3. Insider Threats

### **Methods**
- **Data Theft:** Stealing sensitive information for personal or competitive advantage.
- **Sabotage:** Deliberately damaging systems or data.
- **Espionage:** Passing confidential data to competitors or foreign entities.
- **Negligence:** Unintentional errors or carelessness causing exposure or breaches.

### **Motivations**
- **Financial Gain:** Selling or monetizing stolen information.
- **Revenge:** Retaliation against employer or management.
- **Ideology:** Political, social, or ethical beliefs (hacktivism).
- **Coercion:** Forced by external threat actors or blackmail.
- **Carelessness:** Lack of awareness or disregard for policy.

---

## 4. Historical Examples of Insider Threats

- **Edward Snowden (2013):** Leaked classified NSA documents revealing surveillance programs.
- **Chelsea Manning (2010):** Released military and diplomatic documents to WikiLeaks.
- **Robert Hanssen (FBI Agent):** Spied for the Soviet Union and Russia for over 20 years.
- **Greg Chung (Boeing Engineer):** Stole aerospace data for China.
- **Harold T. Martin (NSA Contractor):** Hoarded classified materials at home, exposing secrets unintentionally.

---

## 5. Security Threat Vector Taxonomy (Willison & Warkentin, 2013)

A structured framework to categorize how threats emerge and act within organizations.  
It focuses on **actors**, **actions**, and **assets** within a cyber ecosystem.

### **Key Components**
1. **Threat Sources (Actors):**
   - External attackers, insiders, competitors, hacktivists.
2. **Threat Actions (Vectors):**
   - The method or pathway (phishing, social engineering, malware).
3. **Threat Consequences (Outcomes):**
   - Data theft, service disruption, financial loss.

This taxonomy emphasizes understanding not just *what* happens, but *how* and *why* a threat manifests.

---

## 6. Straub-Welke Security Action Cycle

A behavioral model explaining how organizations and individuals respond to information security threats.

### **Stages**
1. **Threat Perception:** Recognizing that a threat exists.
2. **Security Action Initiation:** Deciding to take protective measures.
3. **Implementation of Safeguards:** Applying technical, organizational, or behavioral controls.
4. **Review and Adaptation:** Assessing the effectiveness of safeguards and adjusting them as needed.

The model highlights the cyclical, ongoing nature of security management — emphasizing continual awareness and response.

---

## 7. Psychological Neutralization and Fear Appeal in Cybersecurity

### **Psychological Neutralization**
Techniques individuals use to rationalize or justify unethical or noncompliant behavior.

**Common Neutralization Techniques:**
- **Denial of Responsibility:** “It wasn’t my fault.”
- **Denial of Injury:** “No one got hurt.”
- **Denial of Victim:** “They deserved it.”
- **Appeal to Higher Loyalties:** “I did it for the team.”
- **Condemnation of Condemners:** “The system is unfair.”
- **Metaphor of the Ledger:** “I’ve done good things, so this is okay.”


In cybersecurity, employees may neutralize policies (e.g., sharing passwords, ignoring updates) by downplaying their actions’ risks.

### **Fear Appeal**
A persuasive communication technique that motivates protective behavior by emphasizing threat severity and personal vulnerability.

Used in awareness campaigns:
- “Phishing attacks can steal your paycheck — stay alert.”
- “Weak passwords can cost your job.”

However, overly strong fear appeals without efficacy (belief one can act effectively) may backfire and cause avoidance.

---

## 8. Protection Motivation Theory (PMT)

A psychological framework explaining how individuals decide to protect themselves from threats.

### **Core Components**
1. **Threat Appraisal:**
   - **Perceived Severity:** How serious the threat is.
   - **Perceived Vulnerability:** Likelihood of being personally affected.
2. **Coping Appraisal:**
   - **Response Efficacy:** Belief that protective action will work.
   - **Self-Efficacy:** Confidence in one’s ability to take action.
   - **Response Cost:** The perceived burden or cost of action.

### **Cyber Application**
Employees are more likely to follow security policies if they:
- Believe cyber threats are serious and relevant.
- Trust that safeguards (like MFA) are effective.
- Feel capable of implementing them.
- Do not view security actions as overly inconvenient.

PMT is widely used in cybersecurity awareness and training to predict and improve compliance behavior.

---


## 9. Theory of Planned Behavior (TPB)

### **Overview**
The Theory of Planned Behavior (Ajzen, 1991) explains how attitudes, social pressures, and perceived control influence an individual’s intention to perform a behavior — including cybersecurity compliance or violations.

### **Core Components**
1. **Attitude Toward the Behavior**  
   - Personal evaluation of whether the behavior is good or bad.  
   - Example: “Following security protocols helps keep our company safe.”

2. **Subjective Norms**  
   - Perceived social pressure to perform or not perform the behavior.  
   - Example: “My coworkers and supervisor expect me to follow cybersecurity rules.”

3. **Perceived Behavioral Control (PBC)**  
   - The individual’s belief about how easy or difficult it is to perform the behavior.  
   - Example: “I have the knowledge and tools to use secure passwords.”

### **Behavioral Intention**
Behavioral intention represents the motivation to act.  
**Formula (conceptual):**  
`Behavioral Intention = f(Attitude, Subjective Norms, Perceived Behavioral Control)`

### **Cybersecurity Application**
- Employees with **positive attitudes** toward security, **strong norms** promoting compliance, and **confidence** in their ability to comply are more likely to follow security policies.
- Used to design training programs that enhance **perceived control** (through clear instructions) and **social norms** (through leadership modeling secure behavior).

---

## 10. General Deterrence Theory (GDT)

### **Overview**
Derived from criminology, General Deterrence Theory (Beccaria, 1764; Gibbs, 1975) proposes that people refrain from committing violations when they perceive a high likelihood of detection and punishment.

### **Key Components**
1. **Certainty of Punishment:**  
   The belief that rule violations will be detected and punished.

2. **Severity of Punishment:**  
   The perceived harshness or seriousness of the penalty.

3. **Celerity (Swiftness) of Punishment:**  
   The speed at which punishment follows the violation.

### **Cybersecurity Application**
- Employees are less likely to engage in policy violations or insider threats if they believe:
  - Monitoring systems are effective (certainty).  
  - Sanctions are meaningful (severity).  
  - Enforcement is prompt (celerity).

### **Balancing Act**
Overly harsh deterrence measures may cause fear or resentment, reducing cooperation.  
Effective deterrence combines clear policies, consistent enforcement, and fair treatment.

---

## 11. Habituation Theory

### **Overview**
Habituation Theory (Sokolov, 1963; Groves & Thompson, 1970) explains how repeated exposure to the same stimulus decreases responsiveness to it over time.

### **Key Principle**
- When individuals see the same warning or alert repeatedly without experiencing real harm, their **attention and response decline** — they become “numb” to the message.

### **Cybersecurity Application**
- **Warning Fatigue:** Employees ignore repetitive security warnings (e.g., browser SSL alerts, phishing banners).
- **Overexposure:** Frequent but low-impact alerts can reduce perceived importance of genuine threats.

### **Mitigation Strategies**
- Vary the design, frequency, and context of security messages.
- Use adaptive alerts that adjust based on user history or risk level.
- Combine automated warnings with personalized education or just-in-time training.

---

## 12. Dispositional vs. Situational Factors in Cybersecurity Behavior

### **Overview**
Human behavior in cybersecurity contexts can be influenced by both **dispositional (internal)** and **situational (external)** factors.  
Understanding the distinction helps explain why individuals violate or comply with security policies.

### **Dispositional Factors (Person-Centered)**
Internal characteristics that influence behavior:
- **Personality traits:** Conscientiousness, impulsivity, risk-taking.
- **Moral values:** Integrity, ethical standards.
- **Security awareness:** Knowledge and attitudes toward cybersecurity.
- **Cognitive biases:** Overconfidence, optimism bias.

**Example:**  
An employee high in conscientiousness and moral responsibility is more likely to follow cybersecurity guidelines consistently.

### **Situational Factors (Environment-Centered)**
External conditions that shape or trigger behavior:
- **Work environment:** Stress, time pressure, unclear policies.
- **Organizational culture:** Norms of compliance or negligence.
- **Leadership behavior:** Modeling of secure or insecure practices.
- **Technology design:** Ease of use, accessibility of secure alternatives.

**Example:**  
Even well-intentioned employees may bypass security controls if systems are overly complex or deadlines are tight.

### **Interplay of Factors**
- Behavior is best explained by the **interaction** between disposition and situation.  
  Example: A risk-tolerant individual (dispositional) may ignore warnings only when the workplace has weak monitoring (situational).

### **Cybersecurity Implication**
Effective security culture requires:
- Strengthening individual awareness (dispositional influence).
- Designing supportive environments and clear policies (situational influence).

---

## Integrative Perspective

In cybersecurity behavior research:
- **TPB** explains **why** individuals form intentions to comply.
- **GDT** explains **how** deterrence shapes compliance behavior.
- **Habituation** explains **why** individuals may ignore repeated warnings.
- **Dispositional/Situational analysis** provides a **holistic view** of both internal motives and environmental pressures influencing security outcomes.

---

## Summary Table

| Concept | Core Idea | Application |
|----------|------------|-------------|
| **Threat** | Potential harm to systems | Phishing, ransomware |
| **Vulnerability** | System weakness | Outdated software |
| **Safeguard** | Protection mechanism | Encryption, MFA |
| **Risk** | Likelihood x Impact | Used in risk assessment |
| **Threat Vector** | Path of attack | Email, web, network |
| **Insider Threat** | Harm from within | Data theft, sabotage |
| **Willison & Warkentin** | Categorization of threats | Actor-Action-Asset model |
| **Straub-Welke Cycle** | Security response process | Perceive → Act → Review |
| **Neutralization** | Justifying poor behavior | “It’s not my fault” |
| **Fear Appeal** | Using fear to motivate protection | Awareness campaigns |
| **Protection Motivation Theory** | Explains security behavior | Used in training programs |
